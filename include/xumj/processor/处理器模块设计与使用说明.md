# 日志处理器模块设计与使用说明

## 1. 设计思路

### 1.1 整体架构

日志处理器（LogProcessor）模块是分布式实时日志分析与监控系统中的核心组件，负责接收、解析、处理和存储日志数据。模块采用了模块化、插件式的设计，允许用户自定义日志解析器和处理流程。

该模块的主要设计思路包括：

1. **流水线处理**：采用"接收→解析→处理→分析→存储"的流水线处理架构，提高处理效率
2. **插件式解析器**：通过LogParser接口支持不同格式日志的解析
3. **多线程处理**：使用工作线程池并行处理日志数据，提高吞吐量
4. **网络支持**：内置TCP服务器，支持远程日志提交
5. **灵活存储**：支持多种存储后端（Redis和MySQL）

### 1.2 核心类设计

- **LogProcessor**：主处理器类，协调整个处理流程
- **LogParser**：解析器接口，定义了日志解析的标准方法
- **JsonLogParser**：JSON格式日志解析器，处理结构化日志
- **LogData**：原始日志数据结构
- **LogProcessorConfig**：处理器配置类

### 1.3 数据流

```
                  +------------------+
                  |    日志源        |
                  +-------+----------+
                          |
                          v
                  +-------+----------+
                  |    TCP服务器     |
                  +-------+----------+
                          |
                          v
+-----+  接收  +----------+---------+  解析  +----------------+
|外部 +------->+                    +------->+                |
|提交 |        |    日志处理器      |        |   日志解析器    |
+-----+        |   LogProcessor    |        |   LogParser    |
               +----------+---------+        +-------+--------+
                          |                          |
                          v                          v
               +----------+---------+       +--------+---------+
               |    数据队列        |       |   解析后的日志   |
               |    Queue          |       |   LogRecord     |
               +----------+---------+       +--------+--------+
                          |                          |
                          v                          v
               +----------+---------+       +--------+--------+
               |    工作线程        |------>+                 |
               |                   |       |    日志分析器    |
               +----------+---------+       |  LogAnalyzer   |
                          |                 +--------+--------+
                          v                          |
                +---------+----------+               v
                |                    |       +-------+---------+
                |    存储接口        |       |     分析结果    |
                |   Storage          |       |                |
                +---------+----------+       +----------------+
                          |
                          v
          +---------------+---------------+
          |                               |
+---------v----------+       +------------v-------+
|                    |       |                    |
|      Redis存储     |       |     MySQL存储      |
|                    |       |                    |
+--------------------+       +--------------------+
```

## 2. 设计中遇到的难点

### 2.1 日志格式多样性

**难点**：日志格式多样化（结构化日志、半结构化日志、纯文本日志等）导致解析困难。

**解决方案**：
- 设计了抽象LogParser接口
- 实现了基于插件的解析器架构
- JsonLogParser处理JSON格式
- 支持自定义解析器（如TextLogParser）
- 使用元数据机制辅助解析决策

### 2.2 多线程并发处理

**难点**：多线程环境下的并发安全性，特别是处理器状态、连接管理、队列操作等。

**解决方案**：
- 采用线程安全队列存储待处理数据
- 使用互斥锁（std::mutex）保护共享资源
- 使用条件变量（std::condition_variable）实现线程协作
- 采用std::atomic实现无锁计数
- 资源的RAII管理确保异常安全

### 2.3 性能与内存压力

**难点**：处理大量日志时的性能瓶颈和内存压力。

**解决方案**：
- 实现了队列大小限制，防止内存溢出
- 异步处理模式，减少主线程阻塞
- 配置化的线程池大小，适应不同硬件环境
- 减少数据复制，采用移动语义
- 批量处理机制，减少存储操作次数

### 2.4 错误处理与恢复

**难点**：处理不同类型的错误（网络错误、解析错误、存储错误等）并保证系统稳定性。

**解决方案**：
- 分层的异常处理机制
- 失败的日志解析会尝试所有可用解析器
- 存储错误不会中断处理流程
- 自动重试机制
- 全面的日志记录，方便问题诊断

## 3. 技术亮点

### 3.1 高扩展性架构

- **插件式解析器**：开发人员可以轻松添加新的解析器，支持更多日志格式
- **灵活的存储后端**：支持Redis和MySQL，并可扩展到其他存储系统
- **可配置的处理流程**：通过配置控制处理行为，无需修改代码

### 3.2 高性能设计

- **多线程并行处理**：利用多核处理器能力
- **异步IO操作**：网络和存储操作不阻塞主处理流程
- **内存效率**：移动语义和智能指针减少不必要的内存复制和泄漏
- **对象池**：重用对象，减少内存分配和回收开销

### 3.3 强大的集成能力

- **网络模块集成**：内置基于muduo的TCP服务器，支持高性能网络通信
- **分析器集成**：无缝对接日志分析器，支持实时规则匹配和告警
- **存储接口统一**：统一的存储接口，简化多种存储后端的使用

### 3.4 健壮性保障

- **全面的错误处理**：优雅处理各种异常情况
- **优雅的启动和关闭**：确保资源的正确初始化和释放
- **监控指标暴露**：队列大小、处理速率等关键指标可观测

## 4. 使用指南

### 4.1 基本使用流程

1. 创建配置
2. 实例化处理器
3. 添加自定义解析器（可选）
4. 启动处理器
5. 提交日志数据或等待网络连接
6. 处理完成后停止处理器

### 4.2 示例代码

```cpp
#include "xumj/processor/log_processor.h"
#include <iostream>

using namespace xumj::processor;

int main() {
    // 1. 创建配置
    LogProcessorConfig config;
    config.workerThreads = 4;        // 设置工作线程数
    config.queueSize = 10000;        // 设置队列大小
    config.debug = true;             // 启用调试输出
    config.tcpPort = 8001;           // 设置TCP服务器端口
    
    // 2. 创建处理器
    LogProcessor processor(config);
    
    // 3. 添加自定义解析器（可选）
    // 例如添加一个处理纯文本日志的解析器
    class TextLogParser : public LogParser {
    public:
        std::string GetType() const override { return "TextParser"; }
        
        bool Parse(const LogData& logData, xumj::analyzer::LogRecord& record) override {
            // 实现文本日志解析逻辑
            record.id = logData.id;
            record.timestamp = TimestampToString(logData.timestamp);
            record.source = logData.source;
            record.message = logData.message;
            record.level = "INFO";
            return true;
        }
    };
    
    processor.AddLogParser(std::make_shared<TextLogParser>());
    
    // 4. 启动处理器
    if (!processor.Start()) {
        std::cerr << "处理器启动失败" << std::endl;
        return 1;
    }
    
    // 5. 提交日志数据
    LogData data;
    data.id = "log-001";
    data.timestamp = std::chrono::system_clock::now();
    data.source = "example";
    data.message = "这是一条测试日志";
    data.metadata["client_version"] = "1.0.0";
    
    if (processor.SubmitLogData(data)) {
        std::cout << "日志提交成功" << std::endl;
    }
    
    // 或者直接处理JSON字符串
    processor.ProcessJsonString(R"({"level":"INFO","message":"JSON格式日志","timestamp":"2023-07-15T12:34:56"})");
    
    // 等待处理完成
    std::this_thread::sleep_for(std::chrono::seconds(2));
    
    // 6. 停止处理器
    processor.Stop();
    
    return 0;
}
```

### 4.3 配置说明

LogProcessorConfig类支持以下配置选项：

| 配置项 | 类型 | 默认值 | 说明 |
|-------|------|-------|------|
| debug | bool | false | 是否启用调试输出 |
| workerThreads | int | 4 | 工作线程数量 |
| queueSize | int | 10000 | 队列最大容量 |
| tcpPort | int | 8001 | TCP服务器监听端口 |
| enableRedisStorage | bool | true | 是否启用Redis存储 |
| enableMySQLStorage | bool | true | 是否启用MySQL存储 |

### 4.4 自定义解析器

创建自定义解析器需要继承LogParser接口并实现Parse方法：

```cpp
class CustomLogParser : public LogParser {
public:
    std::string GetType() const override {
        return "CustomParser";
    }
    
    bool Parse(const LogData& logData, xumj::analyzer::LogRecord& record) override {
        // 实现自定义解析逻辑
        // 返回true表示解析成功，false表示解析失败
        return true;
    }
};
```

### 4.5 与分析器结合使用

LogProcessor可以与LogAnalyzer结合使用，实现日志的实时分析：

```cpp
// 获取处理器的分析器实例
auto analyzer = processor.GetAnalyzer();

// 添加分析规则
analyzer->AddRule(std::make_shared<xumj::analyzer::RegexAnalysisRule>(
    "ErrorPattern",
    "错误|异常|失败",
    std::vector<std::string>{"error_type"}
));

// 设置分析完成回调
analyzer->SetAnalysisCallback([](const std::string& logId, 
                               const std::unordered_map<std::string, std::string>& results) {
    std::cout << "分析完成：" << logId << std::endl;
    for (const auto& [key, value] : results) {
        std::cout << "  " << key << " = " << value << std::endl;
    }
});
```

## 5. 最佳实践

### 5.1 性能优化

- 根据系统硬件调整工作线程数量（通常为CPU核心数的1-2倍）
- 适当设置队列大小，避免内存压力
- 对于大量小日志，考虑批量提交
- 针对特定日志格式，实现专用解析器提高效率

### 5.2 错误处理

- 始终检查SubmitLogData的返回值
- 实现合理的重试策略
- 在高负载情况下提供降级机制
- 保留原始日志以便于问题排查

### 5.3 安全考虑

- 使用TLS/SSL加密网络连接
- 实现认证机制控制日志提交权限
- 对敏感日志内容进行脱敏处理
- 定期清理旧日志数据

## 6. 常见问题

1. **Q: 处理器启动失败怎么办？**  
   A: 检查网络端口是否被占用，检查存储服务是否可用，确保有足够的系统资源。

2. **Q: 日志解析失败如何处理？**  
   A: 系统会尝试所有可用的解析器，如果都失败，会使用默认值并记录原始消息。

3. **Q: 如何处理高并发日志？**  
   A: 增加工作线程数量，使用更大的队列大小，考虑使用多个处理器实例并进行负载均衡。

4. **Q: 如何监控处理器状态？**  
   A: 使用GetPendingCount方法查看队列大小，在回调中记录处理统计信息。 